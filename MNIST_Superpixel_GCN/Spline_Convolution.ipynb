{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Spline_Convolution.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required packages.\n",
        "!pip install -q torch-cluster -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-spline-conv -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "metadata": {
        "id": "PN0iHjFxyb5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMDvh1OKeuYP"
      },
      "source": [
        "\n",
        "Graph Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import MNISTSuperpixels\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import (SplineConv, global_mean_pool, graclus,\n",
        "                                max_pool, max_pool_x)\n",
        "from torch_geometric.utils import normalized_cut"
      ],
      "metadata": {
        "id": "AsHdsALITAsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = T.Cartesian(cat=False)\n",
        "dataset = MNISTSuperpixels(root=\".\", transform=transform)\n",
        "data = dataset\n",
        "data_size = len(data)\n",
        "train_dataset = data[:int(data_size * 0.8)];\n",
        "test_dataset = data[int(data_size * 0.8):];"
      ],
      "metadata": {
        "id": "weJ8TIs0S2JT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "d = train_dataset"
      ],
      "metadata": {
        "id": "WhLBijYzT_gI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalized_cut_2d(edge_index, pos):\n",
        "    row, col = edge_index\n",
        "    edge_attr = torch.norm(pos[row] - pos[col], p=2, dim=1)\n",
        "    return normalized_cut(edge_index, edge_attr, num_nodes=pos.size(0))"
      ],
      "metadata": {
        "id": "WffkW2SgWpF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = SplineConv(d.num_features, 32, dim=2, kernel_size=5)\n",
        "        self.conv2 = SplineConv(32, 64, dim=2, kernel_size=5)\n",
        "        self.fc1 = torch.nn.Linear(64, 128)\n",
        "        self.fc2 = torch.nn.Linear(128, d.num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        data.x = F.elu(self.conv1(data.x, data.edge_index, data.edge_attr))\n",
        "        weight = normalized_cut_2d(data.edge_index, data.pos)\n",
        "        cluster = graclus(data.edge_index, weight, data.x.size(0))\n",
        "        data.edge_attr = None\n",
        "        data = max_pool(cluster, data, transform=transform)\n",
        "\n",
        "        data.x = F.elu(self.conv2(data.x, data.edge_index, data.edge_attr))\n",
        "        weight = normalized_cut_2d(data.edge_index, data.pos)\n",
        "        cluster = graclus(data.edge_index, weight, data.x.size(0))\n",
        "        x, batch = max_pool_x(cluster, data.x, data.batch)\n",
        "\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        return F.log_softmax(self.fc2(x), dim=1)"
      ],
      "metadata": {
        "id": "sers4YO0ZMxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Net().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "gJQj9biavOJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "\n",
        "    if epoch == 16:\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = 0.001\n",
        "\n",
        "    if epoch == 26:\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = 0.0001\n",
        "\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        F.nll_loss(model(data), data.y).backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "\n",
        "    for data in test_loader:\n",
        "        data = data.to(device)\n",
        "        pred = model(data).max(1)[1]\n",
        "        correct += pred.eq(data.y).sum().item()\n",
        "    return correct / len(test_dataset)"
      ],
      "metadata": {
        "id": "4Bx-BF1IzpDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 31):\n",
        "    train(epoch)\n",
        "    test_acc = test()\n",
        "    print(f'Epoch: {epoch:02d}, Test: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEoun_w0zxB1",
        "outputId": "e81ba3a4-0f38-4200-aa0b-9ef7e617dfac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01, Test: 0.8153\n",
            "Epoch: 02, Test: 0.8590\n",
            "Epoch: 03, Test: 0.8684\n",
            "Epoch: 04, Test: 0.8964\n",
            "Epoch: 05, Test: 0.8702\n",
            "Epoch: 06, Test: 0.9207\n",
            "Epoch: 07, Test: 0.9182\n",
            "Epoch: 08, Test: 0.9246\n",
            "Epoch: 09, Test: 0.9177\n",
            "Epoch: 10, Test: 0.9251\n",
            "Epoch: 11, Test: 0.9270\n",
            "Epoch: 12, Test: 0.9172\n",
            "Epoch: 13, Test: 0.9273\n",
            "Epoch: 14, Test: 0.9308\n",
            "Epoch: 15, Test: 0.9358\n",
            "Epoch: 16, Test: 0.9479\n",
            "Epoch: 17, Test: 0.9496\n",
            "Epoch: 18, Test: 0.9506\n",
            "Epoch: 19, Test: 0.9527\n",
            "Epoch: 20, Test: 0.9491\n",
            "Epoch: 21, Test: 0.9497\n",
            "Epoch: 22, Test: 0.9511\n",
            "Epoch: 23, Test: 0.9484\n",
            "Epoch: 24, Test: 0.9533\n",
            "Epoch: 25, Test: 0.9519\n",
            "Epoch: 26, Test: 0.9514\n",
            "Epoch: 27, Test: 0.9539\n",
            "Epoch: 28, Test: 0.9541\n",
            "Epoch: 29, Test: 0.9513\n",
            "Epoch: 30, Test: 0.9534\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JrpYoSeJ2Amg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}