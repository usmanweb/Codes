{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import nasnet\n",
    "from keras.optimizers import SGD, Adam, Nadam\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint,TensorBoard,ReduceLROnPlateau,EarlyStopping,CSVLogger\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import shutil\n",
    "import h5py\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (256, 256, 3)\n",
    "\n",
    "label_names = {0: 'farm', 1: 'houses', 2: 'others', 3: 'blackfarms'}\n",
    "label_names_inv = {v: k for k,v in label_names.items()}\n",
    "num_classes = len(label_names)\n",
    "\n",
    "batch_size = 16\n",
    "nb_epoch = 200\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_path):\n",
    "    with h5py.File(dataset_path,'r') as f:\n",
    "        dx = f['data_x'][:]\n",
    "        dy = f['data_y'][:]  \n",
    "    return dx, to_categorical(dy, num_classes)\n",
    "\n",
    "def batch_generator(data_X, data_y, batch_size):\n",
    "    indexes = np.array(range(len(data_y)))\n",
    "    n = len(indexes)\n",
    "    while True:\n",
    "        batch_start = 0\n",
    "        batch_end = batch_size\n",
    "        np.random.shuffle(indexes)\n",
    "        while batch_start < n:\n",
    "            index = []\n",
    "            batch_y = []\n",
    "            y = []\n",
    "            index = indexes[batch_start:batch_end]\n",
    "            batch_x = np.array([data_X[i] for i in index])\n",
    "            batch_y = np.array([data_y[i] for i in index])\n",
    "            yield batch_x, batch_y\n",
    "            batch_start += batch_size   \n",
    "            batch_end += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nasnet_large_2d_nadam'\n",
    "dataset_path = 'dataset_2d_new.h5'\n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_dataset(dataset_path)\n",
    "print ('Size of dataset:', len(y))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[1800:], y[1800:]\n",
    "X_val, y_val = X[600:1200], y[600:1200]\n",
    "X_test, y_test = X[:600], y[:600]\n",
    "print('Training: {}\\tValidation: {}\\tTesting: {}'.format(X_train.shape[0], X_val.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "# print('Training: {}\\tValidation: {}\\tTesting: {}'.format(X_train.shape[0], X_val.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not np.any(np.isnan(X_train))\n",
    "assert not np.any(np.isnan(y_train))\n",
    "assert not np.any(np.isnan(X_val))\n",
    "assert not np.any(np.isnan(y_val))\n",
    "assert not np.any(np.isnan(X_test))\n",
    "assert not np.any(np.isnan(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = batch_generator(X_train, y_train, batch_size)\n",
    "val_gen = batch_generator(X_val, y_val, batch_size)\n",
    "test_gen = batch_generator(X_test, y_test, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = inception_v3.InceptionV3(include_top=True, weights=None, input_shape=input_shape, classes=num_classes)\n",
    "model = nasnet.NASNetLarge(include_top=True, weights=None, input_shape=input_shape, classes=num_classes)\n",
    "#model.load_weights(model_name+'/'+model_name+'.h5')\n",
    "\n",
    "model.summary()\n",
    "# sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=K.epsilon(), decay=0.0)\n",
    "nadam = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=K.epsilon(), schedule_decay=0.004)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=nadam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(model_name+'/'+model_name+'.h5', monitor='val_loss', verbose=2, save_best_only=True, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir=model_name, batch_size=batch_size, write_graph=True, write_images=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=7, verbose=2, mode='auto')\n",
    "cvslogger = CSVLogger(model_name+'/'+model_name+'.csv', separator=',', append=True)\n",
    "\n",
    "callbacks = [checkpoint, reduce_lr, cvslogger, tensorboard, earlystop]\n",
    "train_steps = int(len(y_train)//batch_size)\n",
    "val_steps = int(len(y_test)//batch_size)\n",
    "history = model.fit_generator(train_gen, train_steps, epochs=nb_epoch, verbose=1, \n",
    "                    max_queue_size=2, validation_data=val_gen, \n",
    "                    validation_steps=val_steps, shuffle=True,\n",
    "                    workers=1, use_multiprocessing= False, \n",
    "                    initial_epoch=0, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vx, vy = val_gen.next()\n",
    "print (vx.shape, vy.shape)\n",
    "image_input = vx[, :,:,:]\n",
    "print (image_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@### load best weights and make sub model\n",
    "from keras.models import Model, load_model\n",
    "model.load_weights (model_name+'/'+model_name+'.h5')\n",
    "sub_model = Model (inputs = model.input, outputs = model.get_layer('activation_7').output)\n",
    "sub_model.summary()\n",
    "\n",
    "### compute activation of selected layer\n",
    "sub_output = sub_model.predict (vx)\n",
    "print (sub_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "feature = sub_output#[1,:,:,:]#model.predict(batch_imagesX)  # feature is activation of intermediate layer\n",
    "\n",
    "pdf = PdfPages( 'test.pdf' )\n",
    "gs = gridspec.GridSpec(7, 6, top=1., bottom=0., right=1., left=0., hspace=0.,\n",
    "        wspace=0.)\n",
    "i =0\n",
    "for g in gs:\n",
    "    ax = plt.subplot(g)\n",
    "    ax.imshow(feature[2][:,:,i])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_aspect('auto')\n",
    "    i+=1\n",
    "    \n",
    "pdf.savefig()\n",
    "pdf.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_generator(test_gen, steps=len(X_test)//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_generator(test_gen, steps=len(X_test)//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)\n",
    "preds_bin = (preds == preds.max(axis=1, keepdims=True)).astype(int)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_classes = []\n",
    "for p in preds.argmax(axis=1):\n",
    "    pres_classes.append(label_names[p])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_classes = []\n",
    "for p in y_test.argmax(axis=1):\n",
    "    truth_classes.append(label_names[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('comparison3.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['2d_pred'] = pres_classes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.fromarray(X_test[2], 'RGB')\n",
    "img.save('my.png')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(val):\n",
    "    if val.split('_') == ['houses','to','houses']:\n",
    "        return 'others'\n",
    "    if val.split('_')[2] == 'houses':\n",
    "        return 'construction'\n",
    "    if val == 'blackfarms_to_farm':\n",
    "        return 'cultivation'\n",
    "    if val == 'farm_to_blackfarms':\n",
    "        return 'uncultivation'\n",
    "    return 'others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "cc = ['houses', 'farm', 'blackfarms', 'others']\n",
    "for x in product(cc,cc):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "\n",
    "for index in range(0, len(pres_classes), 3):\n",
    "    pred11, pred13, pred17 = pres_classes[index:index+3]\n",
    "    \n",
    "    trans_11_13 = transform(pred11 + '_to_' + pred13)\n",
    "    trans_13_17 = transform(pred13 + '_to_' + pred17)\n",
    "    \n",
    "    if trans_13_17 != 'others':\n",
    "        final_label = trans_13_17\n",
    "    else:\n",
    "        final_label = trans_11_13\n",
    "    \n",
    "    labels.append(final_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('comparison3.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['2d_pred'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = cols[-1:] + cols[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[cols]\n",
    "df.to_csv('comparison5.csv', index=False, header=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['3d_pred'] == df['truth']).sum() / float(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['2d_pred'] == df['truth']).sum() / float(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['2d_inceptionv3'] == df['truth']).sum() / float(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['2d_inception_resnetv2'] == df['truth']).sum() / float(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.all(preds_bin == y_test.astype(int), axis=1)) / float(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = {0: 'others', 1: 'construction', 2: 'cultivation', 3: 'uncultivation'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_index = 0\n",
    "for imgnum in tqdm(range(0,len(preds),3)):\n",
    "#     imgnum = 112\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 20))\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(X_test[imgnum][:,:,::-1])\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(X_test[imgnum+1][:,:,::-1])\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(X_test[imgnum+2][:,:,::-1])\n",
    "    plt.axis('off')\n",
    "\n",
    "    pred_label = labels[label_index]\n",
    "#     truth = class_labels[y_test[imgnum].astype(int)[0]]\n",
    "\n",
    "    preds_msg = 'pred: {}  /\\  truth: X'.format(pred_label)\n",
    "\n",
    "    fig.text(0.1, 0.6, preds_msg, fontsize=12)\n",
    "\n",
    "    plt.savefig('final_results_2d/{}.png'.format(imgnum), bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    label_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
